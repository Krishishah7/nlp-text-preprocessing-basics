{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkGskP4kifRiebMLHr8hJN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishishah7/nlp-text-preprocessing-basics/blob/main/nlp_text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Text Preprocessing\n",
        "\n",
        "This notebook demonstrates basic text preprocessing steps used in Natural Language Processing (NLP).\n"
      ],
      "metadata": {
        "id": "C7098KUL5Xkc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6_Sm-Y55NIA",
        "outputId": "c5c12591-eb6b-4aa9-a498-351f2838853c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"sample_nlp_text.txt\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a6ORKT45gfE",
        "outputId": "57dff12d-e858-4acc-f1d6-db339dd4ac5c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "Artificial Intelligence is transforming the way humans interact with machines.\n",
            "Natural Language Processing allows computers to understand human language.\n",
            "Text preprocessing is an important step in NLP because raw text contains noise.\n",
            "Removing stopwords, punctuation, and converting text to lowercase improves model performance.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Lowercase\n",
        "text = text.lower()\n",
        "\n",
        "# Remove punctuation\n",
        "text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
        "\n",
        "#Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "\n",
        "print(\"\\nOriginal Tokens:\")\n",
        "print(filtered_tokens[:10])\n",
        "\n",
        "print(\"Lemmatized Tokens:\")\n",
        "print(lemmatized_words)\n",
        "\n",
        "print(\"Processed Tokens:\")\n",
        "print(stemmed_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWQm4Fvx6WgF",
        "outputId": "f02de02b-2f1d-4717-9f9f-558083f73257"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original Tokens:\n",
            "['artificial', 'intelligence', 'transforming', 'way', 'humans', 'interact', 'machines', 'natural', 'language', 'processing']\n",
            "Lemmatized Tokens:\n",
            "['artificial', 'intelligence', 'transforming', 'way', 'human', 'interact', 'machine', 'natural', 'language', 'processing', 'allows', 'computer', 'understand', 'human', 'language', 'text', 'preprocessing', 'important', 'step', 'nlp', 'raw', 'text', 'contains', 'noise', 'removing', 'stopwords', 'punctuation', 'converting', 'text', 'lowercase', 'improves', 'model', 'performance']\n",
            "Processed Tokens:\n",
            "['artifici', 'intellig', 'transform', 'way', 'human', 'interact', 'machin', 'natur', 'languag', 'process', 'allow', 'comput', 'understand', 'human', 'languag', 'text', 'preprocess', 'import', 'step', 'nlp', 'raw', 'text', 'contain', 'nois', 'remov', 'stopword', 'punctuat', 'convert', 'text', 'lowercas', 'improv', 'model', 'perform']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pRx5wSWu6xV_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}